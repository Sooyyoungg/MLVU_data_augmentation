{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 3x3 convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from model_resnet import ResNet\n",
    "from model_resnet import ResidualBlock\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 80\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True,\n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "curr_lr = learning_rate\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f} | Accuracy: {:.4f}\"\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item(), acc))\n",
    "\n",
    "    # Decay learning rate\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model, 'resnet_trained_model.ckpt')  # 전체 모델 저장\n",
    "torch.save(model.state_dict(), 'resnet_trained_model_state.ckpt')\n",
    "torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict()\n",
    "}, 'resnet_trained_model_all.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "# Segmentation을 위한 모델 설정\n",
    "deeplab101 = models.segmentation.deeplabv3_resnet101(pretrained=True).eval()\n",
    "\n",
    "#transform\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "forwardtransform = transforms.Compose(\n",
    "    [transforms.Resize((224,224)),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "backtransform = transforms.Compose([transforms.Resize((32,32))]) \n",
    "\n",
    "\n",
    "#DataLoad\n",
    "batch_size = 100\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "stack_seg = []\n",
    "for epoch in range(1):  \n",
    "    \n",
    "    for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data                   \n",
    "        inputs = forwardtransform(inputs)\n",
    "        seg = deeplab101(inputs)['out']                \n",
    "        seg = backtransform(seg) \n",
    "        seg = torch.argmax(seg,dim=1)           # Batchsize x W x H \n",
    "        #여기까지 하시면 각 Batchsize x W x H 의 각 픽셀에 예측되는 픽셀의 클래스 넘버가 부여\n",
    "        # 0이 배경이고 나머지 1~ 는 물체\n",
    "        print(seg.shape)\n",
    "        stack_seg.append(seg)\n",
    "        \n",
    "output = torch.stack(stack_seg, dim=0)\n",
    "torch.save(output, 'segmented_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# data load\n",
    "batch_size = 100\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, shuffle=False)\n",
    "\n",
    "original_images = []\n",
    "for images,_ in test_loader:\n",
    "    original_images.append(images)\n",
    "\n",
    "original_data = torch.stack(original_images, dim=0)\n",
    "segmented_data = torch.load('segmented_data.pt')\n",
    "augmented_data = original_data\n",
    "\n",
    "\n",
    "# data augmentation\n",
    "with torch.no_grad():\n",
    "    for i in range(len(original_data)):\n",
    "        images_batch = original_data[i]\n",
    "        for j in range(len(images_batch)):\n",
    "            image = images_batch[j]\n",
    "            \n",
    "            # image 크기 32x32 중 (m,n)번째 pixel\n",
    "            for m in range(image.shape[1]):\n",
    "                for n in range(image.shape[2]):\n",
    "                    \n",
    "                    # segmentation label이 0으로 배경인 pixel에 대해\n",
    "                    # RGB 모두 0으로 설정해 검정 배경으로 만들어줌\n",
    "                    if segmented_data[i][j][m][n] == 0:\n",
    "                        # i번째 batch의 j번째 image의 (m,n) 위치의 RGB intensity값 0으로 설정\n",
    "                        #이곳을 바꿔가며 RGBB를 생성\n",
    "                        augmented_data[i][j][0][m][n] = 0\n",
    "                        augmented_data[i][j][1][m][n] = 0\n",
    "                        #augmented_data[i][j][2][m][n] = 0\n",
    "        print(i+1,\" batch complete\")\n",
    "        \n",
    "torch.save(augmented_data, 'blue_augmented_data.pt')\n",
    "\n",
    "original_images = []\n",
    "for images,_ in test_loader:\n",
    "    original_images.append(images)\n",
    "\n",
    "original_data = torch.stack(original_images, dim=0)\n",
    "segmented_data = torch.load('segmented_data.pt')\n",
    "augmented_data = original_data\n",
    "\n",
    "\n",
    "# data augmentation\n",
    "with torch.no_grad():\n",
    "    for i in range(len(original_data)):\n",
    "        images_batch = original_data[i]\n",
    "        for j in range(len(images_batch)):\n",
    "            image = images_batch[j]\n",
    "            \n",
    "            # image 크기 32x32 중 (m,n)번째 pixel\n",
    "            for m in range(image.shape[1]):\n",
    "                for n in range(image.shape[2]):\n",
    "                    \n",
    "                    # segmentation label이 0으로 배경인 pixel에 대해\n",
    "                    # RGB 모두 0으로 설정해 검정 배경으로 만들어줌\n",
    "                    if segmented_data[i][j][m][n] == 0:\n",
    "                        # i번째 batch의 j번째 image의 (m,n) 위치의 RGB intensity값 0으로 설정\n",
    "                        #이곳을 바꿔가며 RGBB를 생성\n",
    "                        augmented_data[i][j][0][m][n] = 0\n",
    "                        #augmented_data[i][j][1][m][n] = 0\n",
    "                        augmented_data[i][j][2][m][n] = 0\n",
    "        print(i+1,\" batch complete\")\n",
    "        \n",
    "torch.save(augmented_data, 'green_augmented_data.pt')\n",
    "\n",
    "original_images = []\n",
    "for images,_ in test_loader:\n",
    "    original_images.append(images)\n",
    "\n",
    "original_data = torch.stack(original_images, dim=0)\n",
    "segmented_data = torch.load('segmented_data.pt')\n",
    "augmented_data = original_data\n",
    "\n",
    "\n",
    "# data augmentation\n",
    "with torch.no_grad():\n",
    "    for i in range(len(original_data)):\n",
    "        images_batch = original_data[i]\n",
    "        for j in range(len(images_batch)):\n",
    "            image = images_batch[j]\n",
    "            \n",
    "            # image 크기 32x32 중 (m,n)번째 pixel\n",
    "            for m in range(image.shape[1]):\n",
    "                for n in range(image.shape[2]):\n",
    "                    \n",
    "                    # segmentation label이 0으로 배경인 pixel에 대해\n",
    "                    # RGB 모두 0으로 설정해 검정 배경으로 만들어줌\n",
    "                    if segmented_data[i][j][m][n] == 0:\n",
    "                        # i번째 batch의 j번째 image의 (m,n) 위치의 RGB intensity값 0으로 설정\n",
    "                        #이곳을 바꿔가며 RGBB를 생성\n",
    "                        #augmented_data[i][j][0][m][n] = 0\n",
    "                        augmented_data[i][j][1][m][n] = 0\n",
    "                        augmented_data[i][j][2][m][n] = 0\n",
    "        print(i+1,\" batch complete\")\n",
    "        \n",
    "torch.save(augmented_data, 'red_augmented_data.pt')\n",
    "\n",
    "original_images = []\n",
    "for images,_ in test_loader:\n",
    "    original_images.append(images)\n",
    "\n",
    "original_data = torch.stack(original_images, dim=0)\n",
    "segmented_data = torch.load('segmented_data.pt')\n",
    "augmented_data = original_data\n",
    "\n",
    "\n",
    "# data augmentation\n",
    "with torch.no_grad():\n",
    "    for i in range(len(original_data)):\n",
    "        images_batch = original_data[i]\n",
    "        for j in range(len(images_batch)):\n",
    "            image = images_batch[j]\n",
    "            \n",
    "            # image 크기 32x32 중 (m,n)번째 pixel\n",
    "            for m in range(image.shape[1]):\n",
    "                for n in range(image.shape[2]):\n",
    "                    \n",
    "                    # segmentation label이 0으로 배경인 pixel에 대해\n",
    "                    # RGB 모두 0으로 설정해 검정 배경으로 만들어줌\n",
    "                    if segmented_data[i][j][m][n] == 0:\n",
    "                        # i번째 batch의 j번째 image의 (m,n) 위치의 RGB intensity값 0으로 설정\n",
    "                        #이곳을 바꿔가며 RGBB를 생성\n",
    "                        augmented_data[i][j][0][m][n] = 0\n",
    "                        augmented_data[i][j][1][m][n] = 0\n",
    "                        augmented_data[i][j][2][m][n] = 0\n",
    "        print(i+1,\" batch complete\")\n",
    "        \n",
    "torch.save(augmented_data, 'black_augmented_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_images_index_150 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(100):                               # 100 = len(original_data)\n",
    "        images_batch = segmented_data[i]\n",
    "        for j in range(100):                           # 100 = len(images_batch)\n",
    "            segmented_image = images_batch[j]\n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            object_pixel=0\n",
    "            \n",
    "            for m in range(segmented_image.shape[0]):\n",
    "                for n in range(segmented_image.shape[1]):\n",
    "                    if segmented_image[m][n] != 0:\n",
    "                        object_pixel += 1\n",
    "                        \n",
    "            if object_pixel >= 150:\n",
    "                sorted_images_index_150.append((i*batch_size+(j+1)))\n",
    "    \n",
    "print(\"Thr=150 Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_loader:                             #100 = len(augmented_data) = 10000 / batch_size\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_150):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr=150: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thr 적용해서 Testing\n",
    "\n",
    "#2. Loading Segmented dataset (our dataset)\n",
    "\"\"\"---------------red---------------\"\"\"\n",
    "augmented_data = torch.load('red_augmented_data.pt')\n",
    "label_set = []\n",
    "for _,labels in test_loader:\n",
    "    label_set.append(labels)\n",
    "augmented_labels = torch.stack(label_set, dim=0)\n",
    "\n",
    "print(augmented_data.shape)\n",
    "print(augmented_labels.shape)\n",
    "\n",
    "# Test the model\n",
    "model = torch.load('resnet_trained_model.ckpt')\n",
    "model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_150):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 150 & red: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thr 적용해서 Testing\n",
    "\n",
    "#2. Loading Segmented dataset (our dataset)\n",
    "\"\"\"---------------green---------------\"\"\"\n",
    "augmented_data = torch.load('green_augmented_data.pt')\n",
    "label_set = []\n",
    "for _,labels in test_loader:\n",
    "    label_set.append(labels)\n",
    "augmented_labels = torch.stack(label_set, dim=0)\n",
    "\n",
    "print(augmented_data.shape)\n",
    "print(augmented_labels.shape)\n",
    "\n",
    "# Test the model\n",
    "model = torch.load('resnet_trained_model.ckpt')\n",
    "model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_150):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 150 & green: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thr 적용해서 Testing\n",
    "\n",
    "#2. Loading Segmented dataset (our dataset)\n",
    "\"\"\"---------------blue---------------\"\"\"\n",
    "augmented_data = torch.load('blue_augmented_data.pt')\n",
    "label_set = []\n",
    "for _,labels in test_loader:\n",
    "    label_set.append(labels)\n",
    "augmented_labels = torch.stack(label_set, dim=0)\n",
    "\n",
    "print(augmented_data.shape)\n",
    "print(augmented_labels.shape)\n",
    "\n",
    "# Test the model\n",
    "model = torch.load('resnet_trained_model.ckpt')\n",
    "model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_150):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 150 & blue: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thr 적용해서 Testing\n",
    "\n",
    "#2. Loading Segmented dataset (our dataset)\n",
    "\"\"\"---------------red---------------\"\"\"\n",
    "augmented_data = torch.load('black_augmented_data.pt')\n",
    "label_set = []\n",
    "for _,labels in test_loader:\n",
    "    label_set.append(labels)\n",
    "augmented_labels = torch.stack(label_set, dim=0)\n",
    "\n",
    "print(augmented_data.shape)\n",
    "print(augmented_labels.shape)\n",
    "\n",
    "# Test the model\n",
    "model = torch.load('resnet_trained_model.ckpt')\n",
    "model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(augmented_data)):\n",
    "            images = augmented_data[i].to(device)\n",
    "            labels = augmented_labels[i].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)    \n",
    "            \n",
    "            \"\"\"수정된부분\"\"\"\n",
    "            #index에 들어있는 사진들만 interfere를 진행\n",
    "            for j in range(batch_size):\n",
    "                if( (i*batch_size)+(j+1) in sorted_images_index_150):     \n",
    "                    total += 1\n",
    "                    if( predicted[j]==labels[j]):\n",
    "                        correct += 1\n",
    "\n",
    "    print('Accuracy of the model on the test images about Thr = 150 & black: {} %'.format(100 * correct / total))\n",
    "    \n",
    "#여기까지가 Hypothesis Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train dataset Segmentation ####\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "# Segmentation을 위한 모델 설정\n",
    "deeplab101 = models.segmentation.deeplabv3_resnet101(pretrained=True).eval()\n",
    "\n",
    "#transform\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "forwardtransform = transforms.Compose(\n",
    "    [transforms.Resize((224,224)),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "backtransform = transforms.Compose([transforms.Resize((32,32))]) \n",
    "\n",
    "\n",
    "#DataLoad\n",
    "batch_size = 100\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "stack_seg = []\n",
    "for epoch in range(1):  \n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data                   \n",
    "        inputs = forwardtransform(inputs)\n",
    "        seg = deeplab101(inputs)['out']                \n",
    "        seg = backtransform(seg) \n",
    "        seg = torch.argmax(seg,dim=1)           # Batchsize x W x H \n",
    "        #여기까지 하시면 각 Batchsize x W x H 의 각 픽셀에 예측되는 픽셀의 클래스 넘버가 부여\n",
    "        # 0이 배경이고 나머지 1~ 는 물체\n",
    "        print(seg.shape)\n",
    "        stack_seg.append(seg)\n",
    "        \n",
    "print(\"Segmentation of Trainset Done\")\n",
    "output = torch.stack(stack_seg, dim=0)\n",
    "print(output.shape)\n",
    "torch.save(output, 'segmented_train_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Augmentation #####\n",
    "# -- blue -- #\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# data load\n",
    "batch_size = 100\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                            train=True,\n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size, shuffle=False)\n",
    "\n",
    "original_images = []\n",
    "for images,_ in train_loader:\n",
    "    original_images.append(images)\n",
    "\n",
    "original_data = torch.stack(original_images, dim=0)\n",
    "segmented_data = torch.load('segmented_train_data.pt')\n",
    "augmented_data = original_data\n",
    "sorted_train_images_index_150 = []\n",
    "\n",
    "# data augmentation\n",
    "with torch.no_grad():\n",
    "    for i in range(len(original_data)):\n",
    "        images_batch = original_data[i]\n",
    "        for j in range(len(images_batch)):\n",
    "            image = images_batch[j]\n",
    "            \n",
    "            \n",
    "            object_pixel=0\n",
    "            \n",
    "            for m in range(image.shape[1]):\n",
    "                for n in range(image.shape[2]):\n",
    "                    if segmented_data[i][j][m][n] != 0:\n",
    "                        object_pixel += 1\n",
    "                        \n",
    "            if object_pixel >= 150:\n",
    "                            \n",
    "                # image 크기 32x32 중 (m,n)번째 pixel\n",
    "                for m in range(image.shape[1]):\n",
    "                    for n in range(image.shape[2]):\n",
    "                    \n",
    "                        # segmentation label이 0으로 배경인 pixel에 대해\n",
    "                        # RGB 모두 0으로 설정해 검정 배경으로 만들어줌\n",
    "                        if segmented_data[i][j][m][n] == 0:\n",
    "                            # i번째 batch의 j번째 image의 (m,n) 위치의 RGB intensity값 0으로 설정\n",
    "                            augmented_data[i][j][0][m][n] = 0\n",
    "                            augmented_data[i][j][1][m][n] = 0\n",
    "                            #augmented_data[i][j][2][m][n] = 0\n",
    "                sorted_train_images_index_150.append((i*batch_size+(j+1)))\n",
    "        print(i+1,\" batch complete\")\n",
    "        \n",
    "print(augmented_data.shape)\n",
    "torch.save(augmented_data, 'blue_augmented_train_data.pt')\n",
    "print(len(sorted_train_images_index_150))\n",
    "torch.save(sorted_train_images_index_150,'sorted_train_images_index_150.pt')       \n",
    "        \n",
    "        \n",
    "\n",
    "# -- Green -- #\n",
    "original_images = []\n",
    "for images,_ in train_loader:\n",
    "    original_images.append(images)\n",
    "\n",
    "original_data = torch.stack(original_images, dim=0)\n",
    "segmented_data = torch.load('segmented_train_data.pt')\n",
    "augmented_data = original_data\n",
    "sorted_train_images_index_150 = []\n",
    "\n",
    "# data augmentation\n",
    "with torch.no_grad():\n",
    "    for i in range(len(original_data)):\n",
    "        images_batch = original_data[i]\n",
    "        for j in range(len(images_batch)):\n",
    "            image = images_batch[j]\n",
    "            \n",
    "            \n",
    "            object_pixel=0\n",
    "            \n",
    "            for m in range(image.shape[1]):\n",
    "                for n in range(image.shape[2]):\n",
    "                    if segmented_data[i][j][m][n] != 0:\n",
    "                        object_pixel += 1\n",
    "                        \n",
    "            if object_pixel >= 150:\n",
    "                            \n",
    "                # image 크기 32x32 중 (m,n)번째 pixel\n",
    "                for m in range(image.shape[1]):\n",
    "                    for n in range(image.shape[2]):\n",
    "                    \n",
    "                        # segmentation label이 0으로 배경인 pixel에 대해\n",
    "                        # RGB 모두 0으로 설정해 검정 배경으로 만들어줌\n",
    "                        if segmented_data[i][j][m][n] == 0:\n",
    "                            # i번째 batch의 j번째 image의 (m,n) 위치의 RGB intensity값 0으로 설정\n",
    "                            augmented_data[i][j][0][m][n] = 0\n",
    "                            #augmented_data[i][j][1][m][n] = 0\n",
    "                            augmented_data[i][j][2][m][n] = 0\n",
    "                sorted_train_images_index_150.append((i*batch_size+(j+1)))\n",
    "        print(i+1,\" batch complete\")\n",
    "        \n",
    "print(augmented_data.shape)\n",
    "torch.save(augmented_data, 'green_augmented_train_data.pt')\n",
    "print(len(sorted_train_images_index_150))\n",
    "torch.save(sorted_train_images_index_150,'sorted_train_images_index_150.pt')  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -- Red -- #\n",
    "original_images = []\n",
    "for images,_ in train_loader:\n",
    "    original_images.append(images)\n",
    "\n",
    "original_data = torch.stack(original_images, dim=0)\n",
    "segmented_data = torch.load('segmented_train_data.pt')\n",
    "augmented_data = original_data\n",
    "sorted_train_images_index_150 = []\n",
    "\n",
    "# data augmentation\n",
    "with torch.no_grad():\n",
    "    for i in range(len(original_data)):\n",
    "        images_batch = original_data[i]\n",
    "        for j in range(len(images_batch)):\n",
    "            image = images_batch[j]\n",
    "            \n",
    "            \n",
    "            object_pixel=0\n",
    "            \n",
    "            for m in range(image.shape[1]):\n",
    "                for n in range(image.shape[2]):\n",
    "                    if segmented_data[i][j][m][n] != 0:\n",
    "                        object_pixel += 1\n",
    "                        \n",
    "            if object_pixel >= 150:\n",
    "                            \n",
    "                # image 크기 32x32 중 (m,n)번째 pixel\n",
    "                for m in range(image.shape[1]):\n",
    "                    for n in range(image.shape[2]):\n",
    "                    \n",
    "                        # segmentation label이 0으로 배경인 pixel에 대해\n",
    "                        # RGB 모두 0으로 설정해 검정 배경으로 만들어줌\n",
    "                        if segmented_data[i][j][m][n] == 0:\n",
    "                            # i번째 batch의 j번째 image의 (m,n) 위치의 RGB intensity값 0으로 설정\n",
    "                            #augmented_data[i][j][0][m][n] = 0\n",
    "                            augmented_data[i][j][1][m][n] = 0\n",
    "                            augmented_data[i][j][2][m][n] = 0\n",
    "                sorted_train_images_index_150.append((i*batch_size+(j+1)))\n",
    "        print(i+1,\" batch complete\")\n",
    "        \n",
    "print(augmented_data.shape)\n",
    "torch.save(augmented_data, 'red_augmented_train_data.pt')\n",
    "print(len(sorted_train_images_index_150))\n",
    "torch.save(sorted_train_images_index_150,'sorted_train_images_index_150.pt')  \n",
    "\n",
    "\n",
    "\n",
    "# -- Black -- #\n",
    "original_images = []\n",
    "for images,_ in train_loader:\n",
    "    original_images.append(images)\n",
    "\n",
    "original_data = torch.stack(original_images, dim=0)\n",
    "segmented_data = torch.load('segmented_train_data.pt')\n",
    "augmented_data = original_data\n",
    "sorted_train_images_index_150 = []\n",
    "\n",
    "# data augmentation\n",
    "with torch.no_grad():\n",
    "    for i in range(len(original_data)):\n",
    "        images_batch = original_data[i]\n",
    "        for j in range(len(images_batch)):\n",
    "            image = images_batch[j]\n",
    "            \n",
    "            \n",
    "            object_pixel=0\n",
    "            \n",
    "            for m in range(image.shape[1]):\n",
    "                for n in range(image.shape[2]):\n",
    "                    if segmented_data[i][j][m][n] != 0:\n",
    "                        object_pixel += 1\n",
    "                        \n",
    "            if object_pixel >= 150:\n",
    "                            \n",
    "                # image 크기 32x32 중 (m,n)번째 pixel\n",
    "                for m in range(image.shape[1]):\n",
    "                    for n in range(image.shape[2]):\n",
    "                    \n",
    "                        # segmentation label이 0으로 배경인 pixel에 대해\n",
    "                        # RGB 모두 0으로 설정해 검정 배경으로 만들어줌\n",
    "                        if segmented_data[i][j][m][n] == 0:\n",
    "                            # i번째 batch의 j번째 image의 (m,n) 위치의 RGB intensity값 0으로 설정\n",
    "                            augmented_data[i][j][0][m][n] = 0\n",
    "                            augmented_data[i][j][1][m][n] = 0\n",
    "                            augmented_data[i][j][2][m][n] = 0\n",
    "                sorted_train_images_index_150.append((i*batch_size+(j+1)))\n",
    "        print(i+1,\" batch complete\")\n",
    "        \n",
    "print(augmented_data.shape)\n",
    "torch.save(augmented_data, 'black_augmented_train_data.pt')\n",
    "print(len(sorted_train_images_index_150))\n",
    "torch.save(sorted_train_images_index_150,'sorted_train_images_index_150.pt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Fine-Tuning dataset\n",
    "\n",
    "# Extract labels of train data corresponding to Thr = 150\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 1. Prepare labels of augmented dats\n",
    "\n",
    "augmented_images_label = []\n",
    "augmented_index = torch.load('sorted_train_images_index_150.pt')\n",
    "print(len(augmented_index))\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "#CIFAR-10\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                         train=True,\n",
    "                                         transform = transform,\n",
    "                                         download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data,\n",
    "                                          shuffle=False,\n",
    "                                          batch_size = batch_size)\n",
    "\n",
    "for epoch in range(1):\n",
    "    \n",
    "    for i,data in enumerate(train_loader):\n",
    "        \n",
    "        images,labels = data\n",
    "        for j in range(batch_size):\n",
    "            if ( i*batch_size + (j+1) )in augmented_index:\n",
    "                augmented_images_label.append(labels[j])\n",
    "\n",
    "                \n",
    "print( \"augmented_images_labels has \",len(augmented_images_label) ,\" labels\")\n",
    "\n",
    "torch.save(augmented_images_label,'augmented_images_label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_labor_index_0_500 = [5,8,9,10,12,13,15,19,27,29,30,33,35,38,40,41,43,44,45,47,50,52,53,56,62,66,69,71,78,82,84,85,87,88,92,100]\n",
    "human_labor_index_1_500 = [1,3,6,15,16,20,21,24,27,29,34,37,38,39,46,47,53,56,57,59,61,64,73,76,77,78,81,83,85,95]\n",
    "human_labor_index_2_500 = [4,7,12,13,14,16,23,27,32,34,37,38,39,51,56,57,58,61,63,67,76,79,80,81,82,90,91,95,98]\n",
    "human_labor_index_3_500 = [5,6,12,13,16,19,21,24,25,26,30,31,32,38,40,42,44,47,55,58,63,73,75,76,81,83,84,89,92,95]\n",
    "human_labor_index_4_500 = [6,11,13,14,17,23,27,33,41,50,62,64,69,70,80,83,87,92,93]\n",
    "human_labor_index_5_500 = [3,4,13,23,32,36,48,51,52,61,62,69,71,77,79,96,99]\n",
    "human_labor_index_6_500 = [6,7,37,42,44,45,56,63,66,69,76,77,87,92,97,99]\n",
    "human_labor_index_7_500 = [27,30,31,33,36,40,43,44,45,47,51,61,63,66,72,73,76,77,80,84,85,90,91,95,98,100]\n",
    "human_labor_index_8_500 = [3,7,9,10,14,18,23,24,26,28,31,41,43,46,47,49,53,56,57,72,82,86,90,98]\n",
    "human_labor_index_9_500 = [9,14,17,18,20,23,30,37,41,43,49,54,57,63,69,73,78,79,81,92,99]\n",
    "human_labor_index_10_500 = [18,20,21,22,23,25,43,47,57,62,65,67,75,80,81,82,84,85,91,94,95]\n",
    "human_labor_index_11_500 = [18,22,30,34,35,46,54,57,66,68,73,74,80,82,90,97]\n",
    "human_labor_index_12_500 = [16,20,27,30,41,43,52,58,59,72,76,81,88]\n",
    "human_labor_index_13_500 = [21,29,37,38,48,57,59,70,73,81]\n",
    "human_labor_index_14_500 = [11,12,14,15,18,20,27,46,49,51,52,56,58,59,60,61,63,68,77,83,84,88,90,91,95,97,99]\n",
    "human_labor_index_15_500 = [3,13,14,19,26,28,29,31,44,46,47,52,57,60,62,63,66,67,75,83,84,89,95,96]\n",
    "human_labor_index_16_500 = [9,15,16,18,22,35,48,51,54,57,63,64,80,82,92,95,100]\n",
    "human_labor_index_17_500 = [1,14,18,24,28,29,37,39,41,43,58,59,77,78,79,81,82,86,93]\n",
    "human_labor_index_18_500 = [7,9,16,17,18,21,36,41,42,49,52,53,54,59,66,70,73,91,92,95,98,99,100]\n",
    "human_labor_index_19_500 = [1,2,5,19,28,31,32,47,50,51,52,62,74,81,98]\n",
    "human_labor_index_20_500 = [1,9,10,12,16,20,31,38,40,58,60,64,65,84,89,91,95]\n",
    "human_labor_index_21_500 = [5,9,10,36,37,39,40,41,46,49,50,54,64,78,81,86,96,99]\n",
    "human_labor_index_22_500 = [1,6,8,13,22,28,35,37,42,43,44,45,50,57,58,61,69,71,79,81]\n",
    "human_labor_index_23_500 = [21,22,29,32,36,37,44,49,50,59,63,65,68,79,83,95,100]\n",
    "human_labor_index_24_500 = [4,6,11,23,28,29,31,39,41,47,54,56,57,58,62,64,67,70,72,74,75,81,90,92,94]\n",
    "human_labor_index_25_500 = [1,12,13,18,19,23,42,46,47,55,63,70,75,78,83,84,85,86,88,89,93,94,98]\n",
    "human_labor_index_26_500 = [1,2,9,12,13,18,21,26,29,30,31,35,40,41,52,53,54,57,61,62,63,78,83,87,90,97]\n",
    "human_labor_index_27_500 = [1,2,12,28,29,31,36,37,39,45,46,49,51,63,64,74,81,82,84,89,92,95,96,100]\n",
    "human_labor_index_28_500 = [16,17,18,20,23,26,27,28,35,44,45,53,55,61,63,65,71,79,88,90,95]\n",
    "human_labor_index_29_500 = [13,16,30,31,39,43,47,49,55,64,70,76,78,82,87,89,94 ]\n",
    "human_labor_index_30_500 = [2,5,6,16,21,22,24,27,30,35,38,41,52,55,61,67,72,73,74,86,88,90]\n",
    "human_labor_index_31_500 = [12,13,14,15,19,36,39,42,47,49,54,58,59,63,65,75,82,84,85,89,91,94,95,97,99]\n",
    "human_labor_index_32_500 = [9,10,11,23,32,39,62,73,81,85,86,90,92,98]\n",
    "human_labor_index_33_500 = [10,18,27,29,30,31,46,50,53,57,59,61,68,69,71,86,87,88,91,99,100]\n",
    "human_labor_index_34_500 = [1,5,11,14,18,20,24,26,27,29,33,35,38,42,53,67,75,77,84,85,86,89,93,99]\n",
    "human_labor_index_35_500 =[1,13,32,44,49,52,53,56,65,69,73,74,81,82,84,97]\n",
    "human_labor_index_36_500 =[2,6,10,11,12,15,18,23,33,37,38,44,51,52,55,60,63,74,81,82,88,91,93,95,97,100]\n",
    "human_labor_index_37_500 =[2,5,9,10,12,14,29,36,41,44,45,50,57,63,67,69,74,80,82,87,88,97,100]\n",
    "human_labor_index_38_500 = [7,8,15,18,19,25,28,33,36,37,87,88,93,95,99,100]\n",
    "human_labor_index_39_500 = [2,6,8,10,23,26,34,35,38,40,55,56,61,64,76,78,89,96]\n",
    "human_labor_index_40_500 = [1,2,12,14,21,36,38,41,55,60,64,71,74,76,77,79,85,86,99]\n",
    "human_labor_index_41_500 = [1,15,17,34,35,36,41,55,56,59,62,65,72,78,88,93]\n",
    "human_labor_index_42_500 = [1,13,17,21,29,37,38,45,50,51,52,56,62,82,86,89]\n",
    "human_labor_index_43_500 = [20,26,32,34,42,49,56,58,62,75,76,78,79,80,86,88,90,92]\n",
    "human_labor_index_44_500 = [2,19,20,24,33,34,40,45,49,52,69,86,87,93,95]\n",
    "human_labor_index_45_500 = [1,6,9,11,13,14,18,19,24,26,30,35,41,54,60,65,83,84,93,98,99]\n",
    "human_labor_index_46_500 = [25,32,37,48,51,70,80,87,88,90,98,100]\n",
    "human_labor_index_47_500 = [13,15,21,22,33,37,40,47,48,49,59,62,65,76,83,90,91,96,98]\n",
    "human_labor_index_48_500 = [12,29,31,34,36,45,59,74,75,82,84,92,93,95]\n",
    "human_labor_index_49_500 = [2,18,29,35,40,42,43,45,46,50,54,59,69,78,82,84,88,96,98]\n",
    "\n",
    "index50 = [human_labor_index_0_500 ,\n",
    "human_labor_index_1_500 ,\n",
    "human_labor_index_2_500 ,\n",
    "human_labor_index_3_500 ,\n",
    "human_labor_index_4_500,\n",
    "human_labor_index_5_500 ,\n",
    "human_labor_index_6_500,\n",
    "human_labor_index_7_500 ,\n",
    "human_labor_index_8_500 ,\n",
    "human_labor_index_9_500,\n",
    "human_labor_index_10_500,\n",
    "human_labor_index_11_500,\n",
    "human_labor_index_12_500,\n",
    "human_labor_index_13_500 ,\n",
    "human_labor_index_14_500,\n",
    "human_labor_index_15_500 ,\n",
    "human_labor_index_16_500 ,\n",
    "human_labor_index_17_500 ,\n",
    "human_labor_index_18_500,\n",
    "human_labor_index_19_500,\n",
    "human_labor_index_20_500 ,\n",
    "human_labor_index_21_500 ,\n",
    "human_labor_index_22_500 ,\n",
    "human_labor_index_23_500,\n",
    "human_labor_index_24_500 ,\n",
    "human_labor_index_25_500,\n",
    "human_labor_index_26_500 ,\n",
    "human_labor_index_27_500 ,\n",
    "human_labor_index_28_500 ,\n",
    "human_labor_index_29_500 ,\n",
    "human_labor_index_30_500 ,\n",
    "human_labor_index_31_500 ,\n",
    "human_labor_index_32_500 ,\n",
    "human_labor_index_33_500 ,\n",
    "human_labor_index_34_500,\n",
    "human_labor_index_35_500 ,\n",
    "human_labor_index_36_500 ,\n",
    "human_labor_index_37_500 ,\n",
    "human_labor_index_38_500 ,\n",
    "human_labor_index_39_500 ,\n",
    "human_labor_index_40_500 ,\n",
    "human_labor_index_41_500 ,\n",
    "human_labor_index_42_500 ,\n",
    "human_labor_index_43_500 ,\n",
    "human_labor_index_44_500 ,\n",
    "human_labor_index_45_500 ,\n",
    "human_labor_index_46_500 ,\n",
    "human_labor_index_47_500,\n",
    "human_labor_index_48_500 ,\n",
    "human_labor_index_49_500 ]\n",
    "\n",
    "print(len(index50))\n",
    "\n",
    "\n",
    "A = []\n",
    "total=0\n",
    "\n",
    "for i in range(len(index50)):\n",
    "    indices = index50[i]\n",
    "    total += len(indices)\n",
    "    for j in range(len(indices)):\n",
    "        A.append(indices[j]+100*i)\n",
    "        \n",
    "print(len(A))\n",
    "print(total)\n",
    "\n",
    "\n",
    "torch.save(A,'human_labor_index.pt')\n",
    "torch.save(index50,'index50.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True,\n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epoch = 60\n",
    "learning_rate = 0.0001\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "#1015개에 해당하는 label들만 뽑아내기\n",
    "human_labor_label = []\n",
    "\n",
    "index50 = torch.load('index50.pt')\n",
    "\n",
    "for epoch in range(1):  \n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "        if(i<=49):\n",
    "            inputs, labels = data\n",
    "            for j in range(len(index50[i])):\n",
    "                human_labor_label.append( labels[ index50[i][j]-1 ] )\n",
    "    \n",
    "print(len(human_labor_label))\n",
    "torch.save(human_labor_label,'human_labor_label1015.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We prepare everything\n",
    "# Trainings From now on \n",
    "\n",
    "# Transfer Learning = 0 / Thr = 150 / RRGB\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "# Settings\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 100\n",
    "\n",
    "# Image & Label Setting 4x28519 & 4x28519\n",
    "\n",
    "\n",
    "blue_augmented_data = torch.load('blue_augmented_train_data.pt')\n",
    "green_augmented_data = torch.load('green_augmented_train_data.pt')\n",
    "red_augmented_data = torch.load('red_augmented_train_data.pt')\n",
    "black_augmented_data = torch.load('black_augmented_train_data.pt')\n",
    "sorted_train_images_index_150 = torch.load('sorted_train_images_index_150.pt')\n",
    "augmented_images_label = torch.load('augmented_images_label.pt')\n",
    "print(blue_augmented_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "whole_image = []\n",
    "whole_label = augmented_images_label + augmented_images_label + augmented_images_label + augmented_images_label\n",
    "\n",
    "# Blue\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(blue_augmented_data[i][j])\n",
    "            \n",
    "    if( (i+1)%10 ==0 ):\n",
    "        print(\"Blue : \",i+1,\"/500 completed\")\n",
    "        \n",
    "\n",
    "# Green\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(green_augmented_data[i][j])\n",
    "            \n",
    "    if( (i+1)%10 ==0 ):\n",
    "        print(\"Green : \",i+1,\"/500 completed\")\n",
    "\n",
    "        \n",
    "# Red\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(red_augmented_data[i][j])\n",
    "            \n",
    "    if( (i+1)%10 ==0 ):\n",
    "        print(\"Red : \",i+1,\"/500 completed\")\n",
    "\n",
    "        \n",
    "# Black\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(black_augmented_data[i][j])\n",
    "            \n",
    "    if( (i+1)%10 ==0 ):\n",
    "        print(\"Black : \",i+1,\"/500 completed\")\n",
    "\n",
    "        \n",
    "whole_image = torch.stack(whole_image)\n",
    "whole_label = torch.stack(whole_label)\n",
    "print( \"size of whole_image is\",whole_image.size())\n",
    "print( \"size of whole_label is\",whole_label.size())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from model_resnet import ResNet\n",
    "from model_resnet import ResidualBlock\n",
    "\n",
    "num_epoch = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model Load\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "model = torch.load('resnet_trained_model.ckpt')\n",
    "model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adadelta(model.parameters(), lr=0.001, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "\n",
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "total_step = whole_image.size()[0] // batch_size\n",
    "curr_lr = learning_rate\n",
    "\n",
    "print(whole_image.size())\n",
    "print(whole_label.size())\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # GPU & Shuffle & Transform\n",
    "    whole_image = whole_image.to(device)\n",
    "    whole_label = whole_label.to(device)\n",
    "    \n",
    "    \n",
    "    torch.manual_seed(epoch)\n",
    "    pmtn = torch.randperm(whole_image.size()[0])          #seed를 고정해도 torch.randperm이 선언될때마다 각각은 고정되지만\n",
    "    whole_image=whole_image[pmtn]                         #서로 다른 pmtn을 갖는다 그래서 하나로 고정\n",
    "    whole_label=whole_label[pmtn]    \n",
    "    \n",
    "    whole_image0 = transforms.RandomCrop(32)(transforms.RandomHorizontalFlip()(transforms.Pad(4)(whole_image)))\n",
    "\n",
    "    for i in range(whole_image0.size()[0] // batch_size):\n",
    "        images = whole_image0[i*batch_size:(i+1)*batch_size]\n",
    "        labels = whole_label[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f} | Accuracy: {:.4f}\"\n",
    "                   .format(epoch+1, num_epoch, i+1, total_step, loss.item(), acc))\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print('Accuracy of the fine-tuned model on the test images: {} %'.format(100 * correct / total))\n",
    "        \n",
    "        \n",
    "     # Decay learning rate\n",
    "    if ((epoch+1)%20==0):\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "                \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "# 1. Loading CIFAR dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the fine-tuned model on the test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning = 0 / Thr = Human / RRGB\n",
    "\n",
    "\n",
    "blue_augmented_data = torch.load('blue_augmented_train_data.pt')\n",
    "green_augmented_data = torch.load('green_augmented_train_data.pt')\n",
    "red_augmented_data = torch.load('red_augmented_train_data.pt')\n",
    "black_augmented_data = torch.load('black_augmented_train_data.pt')\n",
    "print(blue_augmented_data.shape)\n",
    "\n",
    "human_labor_index = torch.load('human_labor_index.pt')\n",
    "index50 = torch.load('index50.pt')\n",
    "human_labor_label1015 = torch.load('human_labor_label1015.pt')\n",
    "\n",
    "\n",
    "whole_image = []\n",
    "whole_label = human_labor_label1015 + human_labor_label1015 + human_labor_label1015 + human_labor_label1015\n",
    "\n",
    "# Blue\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(blue_augmented_data[i][j])\n",
    "            \n",
    "print(\"Blue completed\")\n",
    "        \n",
    "\n",
    "# Green\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(green_augmented_data[i][j])\n",
    "            \n",
    "print(\"Green completed\")\n",
    "\n",
    "        \n",
    "# Red\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(red_augmented_data[i][j])\n",
    "            \n",
    "print(\"Red completed\")\n",
    "\n",
    "        \n",
    "# Black\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(black_augmented_data[i][j])\n",
    "            \n",
    "print(\"Black completed\")\n",
    "\n",
    "        \n",
    "whole_image = torch.stack(whole_image)\n",
    "whole_label = torch.stack(whole_label)\n",
    "print( \"size of whole_image is\",whole_image.size())\n",
    "print( \"size of whole_label is\",whole_label.size())\n",
    "torch.save(whole_image,'ft_data_image_1015.pt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from model_resnet import ResNet\n",
    "from model_resnet import ResidualBlock\n",
    "\n",
    "\n",
    "# Model Load\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "model = torch.load('resnet_trained_model.ckpt')\n",
    "model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "total_step = whole_image.size()[0] // batch_size\n",
    "curr_lr = learning_rate\n",
    "\n",
    "print(whole_image.size())\n",
    "print(whole_label.size())\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # GPU & Shuffle & Transform\n",
    "    whole_image = whole_image.to(device)\n",
    "    whole_label = whole_label.to(device)\n",
    "    \n",
    "    \n",
    "    torch.manual_seed(epoch)\n",
    "    pmtn = torch.randperm(whole_image.size()[0])          #seed를 고정해도 torch.randperm이 선언될때마다 각각은 고정되지만\n",
    "    whole_image=whole_image[pmtn]                         #서로 다른 pmtn을 갖는다 그래서 하나로 고정\n",
    "    whole_label=whole_label[pmtn]    \n",
    "    \n",
    "    whole_image0 = transforms.RandomCrop(32)(transforms.RandomHorizontalFlip()(transforms.Pad(4)(whole_image)))\n",
    "\n",
    "    for i in range(whole_image0.size()[0] // batch_size):\n",
    "        images = whole_image0[i*batch_size:(i+1)*batch_size]\n",
    "        labels = whole_label[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f} | Accuracy: {:.4f}\"\n",
    "                   .format(epoch+1, num_epoch, i+1, total_step, loss.item(), acc))\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the fine-tuned model on the test images: {} %'.format(100 * correct / total))\n",
    "        \n",
    "        \n",
    "     # Decay learning rate\n",
    "    if ((epoch+1)%20==0):\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the fine-tuned model on the test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning = X / Thr = 150 / RRGB\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 100\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True,\n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Image & Label Setting 4x28519 & 4x28519\n",
    "\n",
    "\n",
    "blue_augmented_data = torch.load('blue_augmented_train_data.pt')\n",
    "green_augmented_data = torch.load('green_augmented_train_data.pt')\n",
    "red_augmented_data = torch.load('red_augmented_train_data.pt')\n",
    "black_augmented_data = torch.load('black_augmented_train_data.pt')\n",
    "sorted_train_images_index_150 = torch.load('sorted_train_images_index_150.pt')\n",
    "augmented_images_label = torch.load('augmented_images_label.pt')\n",
    "print(blue_augmented_data.shape)\n",
    "\n",
    "\n",
    "whole_image = []\n",
    "whole_label = augmented_images_label + augmented_images_label + augmented_images_label + augmented_images_label\n",
    "\n",
    "# Blue\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(blue_augmented_data[i][j])\n",
    "            \n",
    "    if( (i+1)%10 ==0 ):\n",
    "        print(\"Blue : \",i+1,\"/500 completed\")\n",
    "        \n",
    "\n",
    "# Green\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(green_augmented_data[i][j])\n",
    "            \n",
    "    if( (i+1)%10 ==0 ):\n",
    "        print(\"Green : \",i+1,\"/500 completed\")\n",
    "\n",
    "        \n",
    "# Red\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(red_augmented_data[i][j])\n",
    "            \n",
    "    if( (i+1)%10 ==0 ):\n",
    "        print(\"Red : \",i+1,\"/500 completed\")\n",
    "\n",
    "        \n",
    "# Black\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(black_augmented_data[i][j])\n",
    "            \n",
    "    if( (i+1)%10 ==0 ):\n",
    "        print(\"Black : \",i+1,\"/500 completed\")\n",
    "\n",
    "        \n",
    "print( \"length of whole_image is\",len(whole_image))\n",
    "print( \"length of whole_label is\",len(whole_label))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#50000 from CIFAR-10 Train Data\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(train_loader):\n",
    "        images,labels = data\n",
    "        for j in range(images.size()[0]):\n",
    "            whole_image.append(images[j])\n",
    "            whole_label.append(labels[j])\n",
    "print(\"length of whole_image = \",len(whole_image))\n",
    "print(\"length of whole_label = \",len(whole_label))\n",
    "\n",
    "\n",
    "# Model\n",
    "from model_resnet import ResNet\n",
    "from model_resnet import ResidualBlock\n",
    "\n",
    "num_epoch = 80\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adadelta(model.parameters(), lr=1, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "        \n",
    "        \n",
    "# Training\n",
    "total_step = len(whole_image) // batch_size\n",
    "curr_lr = learning_rate\n",
    "whole_image = torch.stack(whole_image)\n",
    "whole_label = torch.stack(whole_label)\n",
    "print(whole_image.size())\n",
    "print(whole_label.size())\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    #model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # GPU & Shuffle & Transform\n",
    "    whole_image = whole_image.to(device)\n",
    "    whole_label = whole_label.to(device)\n",
    "    \n",
    "    \n",
    "    torch.manual_seed(epoch)\n",
    "    pmtn = torch.randperm(whole_image.size()[0])          #seed를 고정해도 torch.randperm이 선언될때마다 각각은 고정되지만\n",
    "    whole_image=whole_image[pmtn]                         #서로 다른 pmtn을 갖는다 그래서 하나로 고정\n",
    "    whole_label=whole_label[pmtn]    \n",
    "    \n",
    "    whole_image0 = transforms.RandomCrop(32)(transforms.RandomHorizontalFlip()(transforms.Pad(4)(whole_image)))\n",
    "\n",
    "    for i in range(whole_image0.size()[0] // batch_size):\n",
    "        images = whole_image0[i*batch_size:(i+1)*batch_size]\n",
    "        labels = whole_label[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f} | Accuracy: {:.4f}\"\n",
    "                   .format(epoch+1, num_epoch, i+1, total_step, loss.item(), acc))\n",
    "        \n",
    "     # Decay learning rate\n",
    "    if ((epoch+1)%20==0):\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "                \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
    "            \n",
    "            \n",
    "# Test\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the pre-trained model on the test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning = X / Thr = Human / RRGB\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 100\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True,\n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=False)\n",
    "\n",
    "index50 = torch.load('index50.pt')\n",
    "human_labor_label1015 = torch.load('human_labor_label1015.pt')\n",
    "human_labor_index = torch.load('human_labor_index.pt')\n",
    "\n",
    "print('len(index50) : ',len(index50))\n",
    "print('len(human_labor_index) : ',len(human_labor_index))\n",
    "print('len(human_labor_label1015) : ',len(human_labor_label1015))\n",
    "\n",
    "\n",
    "\n",
    "# Prepare Augmented Data\n",
    "\n",
    "blue_augmented_data = torch.load('blue_augmented_train_data.pt')\n",
    "green_augmented_data = torch.load('green_augmented_train_data.pt')\n",
    "red_augmented_data = torch.load('red_augmented_train_data.pt')\n",
    "black_augmented_data = torch.load('black_augmented_train_data.pt')\n",
    "print(blue_augmented_data.shape)\n",
    "\n",
    "\n",
    "whole_image = []\n",
    "whole_label = human_labor_label1015 + human_labor_label1015 + human_labor_label1015 + human_labor_label1015\n",
    "\n",
    "# Blue\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(blue_augmented_data[i][j])\n",
    "            \n",
    "print(\"Blue completed\")\n",
    "        \n",
    "\n",
    "# Green\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(green_augmented_data[i][j])\n",
    "            \n",
    "print(\"Green completed\")\n",
    "\n",
    "        \n",
    "# Red\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(red_augmented_data[i][j])\n",
    "            \n",
    "print(\"Red completed\")\n",
    "\n",
    "        \n",
    "# Black\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(black_augmented_data[i][j])\n",
    "            \n",
    "print(\"Black completed\")\n",
    "\n",
    "        \n",
    "print( \"length of whole_image is\",len(whole_image))\n",
    "print( \"length of whole_label is\",len(whole_label))\n",
    "\n",
    "# Extract 50000 from CIAFR-10 Train Data\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(train_loader):\n",
    "        images,labels = data\n",
    "        for j in range(images.size()[0]):\n",
    "            whole_image.append(images[j])\n",
    "            whole_label.append(labels[j])\n",
    "print(\"length of whole_image = \",len(whole_image))\n",
    "print(\"length of whole_label = \",len(whole_label))\n",
    "\n",
    "\n",
    "# Model\n",
    "from model_resnet import ResNet\n",
    "from model_resnet import ResidualBlock\n",
    "\n",
    "num_epoch = 160\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adadelta(model.parameters(), lr=1, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "        \n",
    "        \n",
    "# Training     \n",
    "total_step = len(whole_image) // batch_size\n",
    "curr_lr = learning_rate\n",
    "whole_image = torch.stack(whole_image)\n",
    "whole_label = torch.stack(whole_label)\n",
    "print(whole_image.size())\n",
    "print(whole_label.size())\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    #model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # GPU & Shuffle & Transform\n",
    "    whole_image = whole_image.to(device)\n",
    "    whole_label = whole_label.to(device)\n",
    "    \n",
    "    \n",
    "    torch.manual_seed(epoch)\n",
    "    pmtn = torch.randperm(whole_image.size()[0])          #seed를 고정해도 torch.randperm이 선언될때마다 각각은 고정되지만\n",
    "    whole_image=whole_image[pmtn]                         #서로 다른 pmtn을 갖는다 그래서 하나로 고정\n",
    "    whole_label=whole_label[pmtn]    \n",
    "    \n",
    "    whole_image0 = transforms.RandomCrop(32)(transforms.RandomHorizontalFlip()(transforms.Pad(4)(whole_image)))\n",
    "\n",
    "    for i in range(whole_image0.size()[0] // batch_size):\n",
    "        images = whole_image0[i*batch_size:(i+1)*batch_size]\n",
    "        labels = whole_label[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f} | Accuracy: {:.4f}\"\n",
    "                   .format(epoch+1, num_epoch, i+1, total_step, loss.item(), acc))\n",
    "        \n",
    "     # Decay learning rate\n",
    "    if ((epoch+1)%20==0):\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "                \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
    "        \n",
    "# Test\n",
    "#Test the pre_trained Model\n",
    "\n",
    "# 1. Loading CIFAR dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning = 0 / Thr = 150 / 7 Background\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Settings & Load\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "background1 = torch.load('background1.pt')\n",
    "background2 = torch.load('background2.pt')\n",
    "background3 = torch.load('background3.pt')\n",
    "background4 = torch.load('background4.pt')\n",
    "background5 = torch.load('background5.pt')\n",
    "background6 = torch.load('background6.pt')\n",
    "background7 = torch.load('background7.pt')\n",
    "\n",
    "sorted_train_images_index_150 = torch.load('sorted_train_images_index_150.pt')\n",
    "augmented_images_label = torch.load('augmented_images_label.pt')\n",
    "\n",
    "\n",
    "# Image & Label Setting 4x28519 & 4x28519\n",
    "# Label\n",
    "\n",
    "whole_label = []\n",
    "for i in range(7):\n",
    "    whole_label += augmented_images_label\n",
    "\n",
    "    \n",
    "# Image\n",
    "whole_image = []\n",
    "  \n",
    "\n",
    "# backgound1\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background1[i][j])\n",
    "    if ((i+1) % 100 == 0) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background2\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background2[i][j])\n",
    "    if ((i+1) % 100 ==0) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "        \n",
    "# background3\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background3[i][j])\n",
    "    if ((i+1) % 100 == 0) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background4\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background4[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background5\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background5[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background6\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background6[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background7\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background7[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "\n",
    "print(\"whole_image = \", len(whole_image))\n",
    "print(\"whole_label = \", len(whole_label))\n",
    "whole_image = torch.stack(whole_image)\n",
    "whole_label = torch.stack(whole_label)\n",
    "print(whole_image.size())\n",
    "print(whole_label.size())\n",
    "print(\"28519*7 = \",28519*7)\n",
    "\n",
    "\n",
    "# Model \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from model_resnet import ResNet\n",
    "from model_resnet import ResidualBlock\n",
    "\n",
    "num_epoch = 80\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "model = torch.load('resnet_trained_model.ckpt')\n",
    "model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adadelta(model.parameters(), lr=0.001, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "        \n",
    "# Training\n",
    "total_step = whole_image.size()[0] // batch_size\n",
    "curr_lr = learning_rate\n",
    "\n",
    "print(whole_image.size())\n",
    "print(whole_label.size())\n",
    "\n",
    "model.train()\n",
    "\n",
    "max_acc = 0\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # GPU & Shuffle & Transform\n",
    "    whole_image = whole_image.to(device)\n",
    "    whole_label = whole_label.to(device)\n",
    "    \n",
    "    \n",
    "    torch.manual_seed(epoch)\n",
    "    pmtn = torch.randperm(whole_image.size()[0])          #seed를 고정해도 torch.randperm이 선언될때마다 각각은 고정되지만\n",
    "    whole_image=whole_image[pmtn]                         #서로 다른 pmtn을 갖는다 그래서 하나로 고정\n",
    "    whole_label=whole_label[pmtn]    \n",
    "    \n",
    "    whole_image0 = transforms.RandomCrop(32)(transforms.RandomHorizontalFlip()(transforms.Pad(4)(whole_image)))\n",
    "\n",
    "    for i in range(whole_image0.size()[0] // batch_size):\n",
    "        images = whole_image0[i*batch_size:(i+1)*batch_size]\n",
    "        labels = whole_label[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f} | Accuracy: {:.4f}\"\n",
    "                   .format(epoch+1, num_epoch, i+1, total_step, loss.item(), acc))\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print('Accuracy of the fine-tuned model on the test images: {} %'.format(100 * correct / total))\n",
    "        \n",
    "        if max_acc < 100 * correct / total :\n",
    "            max_acc = 100 * correct / total\n",
    "        \n",
    "     # Decay learning rate\n",
    "    if ((epoch+1)%20==0):\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "                \n",
    "print(max_acc)\n",
    "\n",
    "# Test the model\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the fine-tuned model on the test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranfer Learning = 0 / Thr = Human / 7 Backgrounds\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True,\n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epoch = 80\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "background1 = torch.load('background1.pt')\n",
    "background2 = torch.load('background2.pt')\n",
    "background3 = torch.load('background3.pt')\n",
    "background4 = torch.load('background4.pt')\n",
    "background5 = torch.load('background5.pt')\n",
    "background6 = torch.load('background6.pt')\n",
    "background7 = torch.load('background7.pt')\n",
    "\n",
    "human_labor_index = torch.load('human_labor_index.pt')\n",
    "#sorted_train_images_index_150 = torch.load('sorted_train_images_index_150.pt')\n",
    "human_labor_label1015 = torch.load('human_labor_label1015.pt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Image & Label \n",
    "\n",
    "\n",
    "# Label\n",
    "\n",
    "whole_label = []\n",
    "for i in range(7):\n",
    "    whole_label += human_labor_label1015\n",
    "\n",
    "    \n",
    "    \n",
    "# Image\n",
    "\n",
    "whole_image = []\n",
    "  \n",
    "\n",
    "# backgound1\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background1[i][j])\n",
    "    if ((i+1) % 100 == 0) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background2\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background2[i][j])\n",
    "    if ((i+1) % 100 ==0) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "        \n",
    "# background3\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background3[i][j])\n",
    "    if ((i+1) % 100 == 0) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background4\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background4[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background5\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background5[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background6\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background6[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background7\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background7[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "\n",
    "print(\"whole_image = \", len(whole_image))\n",
    "print(\"whole_label = \", len(whole_label))\n",
    "whole_image = torch.stack(whole_image)\n",
    "whole_label = torch.stack(whole_label)\n",
    "print(whole_image.size())\n",
    "print(whole_label.size())\n",
    "print(\"28519*7 = \",28519*7)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from model_resnet import ResNet\n",
    "from model_resnet import ResidualBlock\n",
    "\n",
    "\n",
    "# Model Load\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "model = torch.load('resnet_trained_model.ckpt')\n",
    "model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "total_step = whole_image.size()[0] // batch_size\n",
    "curr_lr = learning_rate\n",
    "\n",
    "print(whole_image.size())\n",
    "print(whole_label.size())\n",
    "\n",
    "model.train()\n",
    "\n",
    "max_acc = 0\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # GPU & Shuffle & Transform\n",
    "    whole_image = whole_image.to(device)\n",
    "    whole_label = whole_label.to(device)\n",
    "    \n",
    "    \n",
    "    torch.manual_seed(epoch)\n",
    "    pmtn = torch.randperm(whole_image.size()[0])          #seed를 고정해도 torch.randperm이 선언될때마다 각각은 고정되지만\n",
    "    whole_image=whole_image[pmtn]                         #서로 다른 pmtn을 갖는다 그래서 하나로 고정\n",
    "    whole_label=whole_label[pmtn]    \n",
    "    \n",
    "    whole_image0 = transforms.RandomCrop(32)(transforms.RandomHorizontalFlip()(transforms.Pad(4)(whole_image)))\n",
    "\n",
    "    for i in range(whole_image0.size()[0] // batch_size):\n",
    "        images = whole_image0[i*batch_size:(i+1)*batch_size]\n",
    "        labels = whole_label[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f} | Accuracy: {:.4f}\"\n",
    "                   .format(epoch+1, num_epoch, i+1, total_step, loss.item(), acc))\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the fine-tuned model on the test images: {} %'.format(100 * correct / total))\n",
    "     \n",
    "    if max_acc < 100 * correct / total :\n",
    "        max_acc = 100 * correct / total\n",
    "        \n",
    "     # Decay learning rate\n",
    "    if ((epoch+1)%20==0):\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "                \n",
    "            \n",
    "print(max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning = X / Thr = 150 / 7 Backgrounds\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Settings & Load\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "background1 = torch.load('background1.pt')\n",
    "background2 = torch.load('background2.pt')\n",
    "background3 = torch.load('background3.pt')\n",
    "background4 = torch.load('background4.pt')\n",
    "background5 = torch.load('background5.pt')\n",
    "background6 = torch.load('background6.pt')\n",
    "background7 = torch.load('background7.pt')\n",
    "\n",
    "sorted_train_images_index_150 = torch.load('sorted_train_images_index_150.pt')\n",
    "augmented_images_label = torch.load('augmented_images_label.pt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True,\n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False)\n",
    "\n",
    "whole_image = []\n",
    "whole_label = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(train_loader):\n",
    "        images,labels = data\n",
    "        for j in range(images.size()[0]):\n",
    "            whole_image.append(images[j])\n",
    "            whole_label.append(labels[j])\n",
    "print(\"length of whole_image = \",len(whole_image))\n",
    "print(\"length of whole_label = \",len(whole_label))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Image & Label Setting 4x28519 & 4x28519\n",
    "\n",
    "\n",
    "# Label\n",
    "\n",
    "#whole_label = []\n",
    "for i in range(7):\n",
    "    whole_label += augmented_images_label\n",
    "\n",
    "    \n",
    "    \n",
    "# Image\n",
    "\n",
    "#whole_image = []\n",
    "  \n",
    "\n",
    "# backgound1\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background1[i][j])\n",
    "    if ((i+1) % 100 == 0) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background2\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background2[i][j])\n",
    "    if ((i+1) % 100 ==0) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "        \n",
    "# background3\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background3[i][j])\n",
    "    if ((i+1) % 100 == 0) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background4\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background4[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background5\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background5[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background6\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background6[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background7\n",
    "for i in range(500):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in sorted_train_images_index_150:\n",
    "            whole_image.append(background7[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "\n",
    "print(\"whole_image = \", len(whole_image))\n",
    "print(\"whole_label = \", len(whole_label))\n",
    "whole_image = torch.stack(whole_image)\n",
    "whole_label = torch.stack(whole_label)\n",
    "print(whole_image.size())\n",
    "print(whole_label.size())\n",
    "print(\"28519*7 + 50000= \",28519*7 + 50000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from model_resnet import ResNet\n",
    "from model_resnet import ResidualBlock\n",
    "\n",
    "num_epoch = 200\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model Load\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "#model = torch.load('resnet_trained_model.ckpt')\n",
    "#model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adadelta(model.parameters(), lr=0.001, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "\n",
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "total_step = whole_image.size()[0] // batch_size\n",
    "curr_lr = learning_rate\n",
    "\n",
    "print(whole_image.size())\n",
    "print(whole_label.size())\n",
    "\n",
    "model.train()\n",
    "\n",
    "max_acc = 0\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # GPU & Shuffle & Transform\n",
    "    whole_image = whole_image.to(device)\n",
    "    whole_label = whole_label.to(device)\n",
    "    \n",
    "    \n",
    "    torch.manual_seed(epoch)\n",
    "    pmtn = torch.randperm(whole_image.size()[0])          #seed를 고정해도 torch.randperm이 선언될때마다 각각은 고정되지만\n",
    "    whole_image=whole_image[pmtn]                         #서로 다른 pmtn을 갖는다 그래서 하나로 고정\n",
    "    whole_label=whole_label[pmtn]    \n",
    "    \n",
    "    whole_image0 = transforms.RandomCrop(32)(transforms.RandomHorizontalFlip()(transforms.Pad(4)(whole_image)))\n",
    "\n",
    "    for i in range(whole_image0.size()[0] // batch_size):\n",
    "        images = whole_image0[i*batch_size:(i+1)*batch_size]\n",
    "        labels = whole_label[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f} | Accuracy: {:.4f}\"\n",
    "                   .format(epoch+1, num_epoch, i+1, total_step, loss.item(), acc))\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print('Accuracy of the fine-tuned model on the test images: {} %'.format(100 * correct / total))\n",
    "        \n",
    "        if max_acc < 100 * correct / total :\n",
    "            max_acc = 100 * correct / total\n",
    "        \n",
    "     # Decay learning rate\n",
    "    if ((epoch+1)%20==0):\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "                \n",
    "print(max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning = X / Thr = Human / 7 Backgrounds\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Settings & Load\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "background1 = torch.load('background1.pt')\n",
    "background2 = torch.load('background2.pt')\n",
    "background3 = torch.load('background3.pt')\n",
    "background4 = torch.load('background4.pt')\n",
    "background5 = torch.load('background5.pt')\n",
    "background6 = torch.load('background6.pt')\n",
    "background7 = torch.load('background7.pt')\n",
    "\n",
    "sorted_train_images_index_150 = torch.load('sorted_train_images_index_150.pt')\n",
    "augmented_images_label = torch.load('augmented_images_label.pt')\n",
    "\n",
    "index50 = torch.load('index50.pt')\n",
    "human_labor_label1015 = torch.load('human_labor_label1015.pt')\n",
    "human_labor_index = torch.load('human_labor_index.pt')\n",
    "\n",
    "print('len(index50) : ',len(index50))\n",
    "print('len(human_labor_index) : ',len(human_labor_index))\n",
    "print('len(human_labor_label1015) : ',len(human_labor_label1015))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True,\n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False)\n",
    "\n",
    "whole_image = []\n",
    "whole_label = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(train_loader):\n",
    "        images,labels = data\n",
    "        for j in range(images.size()[0]):\n",
    "            whole_image.append(images[j])\n",
    "            whole_label.append(labels[j])\n",
    "print(\"length of whole_image = \",len(whole_image))\n",
    "print(\"length of whole_label = \",len(whole_label))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Image & Label Setting 4x28519 & 4x28519\n",
    "\n",
    "\n",
    "# Label\n",
    "\n",
    "#whole_label = []\n",
    "for i in range(7):\n",
    "    whole_label += human_labor_label1015\n",
    "\n",
    "    \n",
    "    \n",
    "# Image\n",
    "\n",
    "#whole_image = []\n",
    "  \n",
    "\n",
    "# backgound1\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background1[i][j])\n",
    "    if ((i+1) % 100 == 0) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background2\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background2[i][j])\n",
    "    if ((i+1) % 100 ==0) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "        \n",
    "# background3\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background3[i][j])\n",
    "    if ((i+1) % 100 == 0) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background4\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background4[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background5\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background5[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background6\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background6[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "# background7\n",
    "for i in range(50):\n",
    "    for j in range(100):    \n",
    "        if ( i*batch_size + (j+1) ) in human_labor_index:\n",
    "            whole_image.append(background7[i][j])\n",
    "    if ((i+1) % 100 == 0 ) :\n",
    "        print(\"{}/500 Done\".format(i+1))\n",
    "            \n",
    "\n",
    "print(\"whole_image = \", len(whole_image))\n",
    "print(\"whole_label = \", len(whole_label))\n",
    "whole_image = torch.stack(whole_image)\n",
    "whole_label = torch.stack(whole_label)\n",
    "print(whole_image.size())\n",
    "print(whole_label.size())\n",
    "print(\"1015*7 +50000= \",1015*7 + 50000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from model_resnet import ResNet\n",
    "from model_resnet import ResidualBlock\n",
    "\n",
    "num_epoch = 160\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model Load\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "#model = torch.load('resnet_trained_model.ckpt')\n",
    "#model.load_state_dict(torch.load('resnet_trained_model_state.ckpt'))\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adadelta(model.parameters(), lr=0.001, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "\n",
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "total_step = whole_image.size()[0] // batch_size\n",
    "curr_lr = learning_rate\n",
    "\n",
    "print(whole_image.size())\n",
    "print(whole_label.size())\n",
    "\n",
    "model.train()\n",
    "\n",
    "max_acc = 0\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # GPU & Shuffle & Transform\n",
    "    whole_image = whole_image.to(device)\n",
    "    whole_label = whole_label.to(device)\n",
    "    \n",
    "    \n",
    "    torch.manual_seed(epoch)\n",
    "    pmtn = torch.randperm(whole_image.size()[0])          #seed를 고정해도 torch.randperm이 선언될때마다 각각은 고정되지만\n",
    "    whole_image=whole_image[pmtn]                         #서로 다른 pmtn을 갖는다 그래서 하나로 고정\n",
    "    whole_label=whole_label[pmtn]    \n",
    "    \n",
    "    whole_image0 = transforms.RandomCrop(32)(transforms.RandomHorizontalFlip()(transforms.Pad(4)(whole_image)))\n",
    "\n",
    "    for i in range(whole_image0.size()[0] // batch_size):\n",
    "        images = whole_image0[i*batch_size:(i+1)*batch_size]\n",
    "        labels = whole_label[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f} | Accuracy: {:.4f}\"\n",
    "                   .format(epoch+1, num_epoch, i+1, total_step, loss.item(), acc))\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print('Accuracy of the fine-tuned model on the test images: {} %'.format(100 * correct / total))\n",
    "        \n",
    "        if max_acc < 100 * correct / total :\n",
    "            max_acc = 100 * correct / total\n",
    "        \n",
    "     # Decay learning rate\n",
    "    if ((epoch+1)%20==0):\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "                \n",
    "\n",
    "            \n",
    "print(max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
